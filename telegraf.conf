# QE Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply prepend
# them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
# for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)


##################################################################################################
#
#    General Telegraf Set-Up
#
##################################################################################################


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
  ## output, and will flush this buffer on a successful write. Oldest metrics
  ## are dropped first when this buffer fills.
  ## This buffer only fills when writes fail to output plugin(s).
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Logging configuration:
  ## Run telegraf with debug log messages.
  debug = false
  ## Run telegraf in quiet mode (error log messages only).
  quiet = false
  ## Specify the log file name. The empty string means to log to stderr.
  logfile = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false



##################################################################################################
#
#    Plugin Set-Up:  
#       Setting up how to input logs and output data.  
#
##################################################################################################



###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Configuration for sending metrics to InfluxDB
[[outputs.influxdb]]
  urls = ["http://localhost:8086"] # required

  ## The target database for metrics; will be created as needed.
  ## For UDP url endpoint database needs to be configured on server side.
  database = "QE"


###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Stream and parse log file(s).
[[inputs.logparser]]
    ## Log files to parse.
    ## These accept standard unix glob matching rules, but with the addition of
       files = ["/ExampleLogs/*.log"]


    ## Read files that currently exist from the beginning. Files that are created
    ## while telegraf is running (and that match the "files" globs) will always
    ## be read from the beginning.
       from_beginning = true


    ## Parse logstash-style "grok" patterns:
       [inputs.logparser.grok]
       ## This is a list of patterns to check the given log file(s) for.
       ## Note that adding patterns here increases processing time. The most
       ## efficient configuration is to have one pattern per logparser.

          patterns = ['''
		     \[Time=%{TIMESTAMP_ISO8601:time:ts-"2006-01-02 15:04:04.000-07:00"}\]\[Acc=%{DATA:Account}\]\[User=%{DATA:User}\]\[Comp=%{DATA:Comp}\]\[App=%{DATA:App}\]\[PID=%{DATA:PID}\]\[Inst=%{DATA:Inst}\](\[Conn=%{DATA:Conn}\])?\[Type=%{DATA:type}\]%{DATA:Message}(Preparing next acquisition with: <\?xml version="1.0" encoding="%{DATA:Encoding:tag}" standalone="%{DATA:Standalone}"\?> <InstrumentD ... %{DATA:TEST}(</RawFileName>     <MethodFileName)?(ame)?>%{DATA:MethodFileName}</MethodFileName>     <SequenceFileName>%{DATA:SequenceFileName}</SequenceFileName>     <SequenceRow>%{NUMBER:SequenceRow}</SequenceRow>     <StartMode>%{NUMBER:StartMode}</StartMode>     <Vial>%{DATA:Vial}</Vial>     <InjVolume>%{NUMBER:InjVolume}</InjVolume>     <Flags>%{NUMBER:Flags}</Flags>   </RunSettings> </InstrumentData>)?(using)?( )?({ExactiveService, Version=%{DATA}, Culture=%{DATA:CultureExactiveService}, PublicKeyToken=%{DATA:PublicKeyTokenExactiveService}, "%{DATA:URLExactiveService}"", Release"\};)?( )?(\{ExactiveManager, Version=%{DATA}, Culture=%{DATA:CultureExactiveManager}, PublicKeyToken=%{DATA:PublicKeyTokenExactiveManager}, "%{DATA:ExactiveManagerURL}"", Release"\};)?( )?(\{ThermoFisher.Foundation.IO, Version=%{DATA}, Culture=%{DATA:CultureThermoFisher}, PublicKeyToken=%{DATA:PublicKeyTokenThermoFisher}, %{DATA:ThermoFisherURL}", "\};)?( )?(\{ThermoFisher.CommonCore.Data, Version=%{DATA}, Culture=%{DATA:CultureThermoFisherCommonCore}, PublicKeyToken=%{DATA:PublicKeyTokenThermoFisherCommonCore}, "%{DATA:ThermoFisherCommonCoreURL}"", "\};)?( )?(\{Exactive, Version=%{DATA}, Culture=%{DATA:CultureExactive}, PublicKeyToken=%{DATA:PublicKeyTokenExactive}, "%{DATA:ExactiveURL}"", Release"\};)?( )?(\{mscorlib, Version=%{DATA}, Culture=%{DATA:CultureMscorlib}, PublicKeyToken=%{DATA:PublicKeyTokenMscorlib}, "%{DATA:mscorlibURL}"", "\})?$
		     ''']

       ## Name of the outputted measurement name.
          measurement = "QELogs"



# Stream a log file, like the tail -f command
[[inputs.tail]]
    ## files to tail.
       files = ["/ExampleLogs/*.log"]

    ## Read file from beginning.
       from_beginning = true

    ## Whether file is a named pipe
       pipe = false

    ##Change the name of the measurement created in InfluxDB
	name_override = "QETemps"

    ## Data format to consume.
       data_format = "grok"

          grok_patterns = ['''
                          %{BONUS}%{NUMBER:Seconds:float}\t%{TIMESTAMP_ISO8601:timestamp:ts-"2006-01-02 15:04:05"}\t%{NUMBER:Uptime:float}\t%{SCINUM:Vaccum1:float}\t%{SCINUM:Vaccum2:float}\t%{SCINUM:Vaccum3:float}\t%{SCINUM:Vaccum4:float}\t%{NUMBER:T1TempBearingR:float}\t%{NUMBER:T1TempMotorR:float}\t%{NUMBER:T1TempBottomPartR:float}\t%{NUMBER:T1TempPowerstageR:float}\t%{NUMBER:T1TempElecR:float}\t%{NUMBER:T1VoltR:float}\t%{NUMBER:T1CurrR:float}\t%{NUMBER:T2TempBearingR:float}\t%{NUMBER:T2TempMotorR:float}\t%{NUMBER:T2TempBottomPartR:float}\t%{NUMBER:T2TempPowerstageR:float}\t%{NUMBER:T2TempElecR:float}\t%{NUMBER:T2VoltR:float}\t%{NUMBER:T2CurrR:float}\t%{NUMBER:T3TempBearingR:float}\t%{NUMBER:T3TempMotorR:float}\t%{NUMBER:T3TempBottomPartR:float}\t%{NUMBER:T3TempPowerstageR:float}\t%{NUMBER:T3TempElecR:float}\t%{NUMBER:T3VoltR:float}\t%{NUMBER:T3CurrR:float}\t%{NUMBER:AmbientTemp:float}\t%{NUMBER:AmbientHumid:float}\t%{NUMBER:CapillaryTemp:float}\t%{NUMBER:HeatsinkTemp:float}\t%{NUMBER:RF01Freq:float}\t%{NUMBER:RF23Freq:float}\t%{NUMBER:CtrapRFAmp:float}\t%{NUMBER:CtrapAmpcurrent:float}\t%{NUMBER:CtrapFreq:float}\t%{NUMBER:CEPosElecTemp:float}\t%{NUMBER:CENegElecTremp:float}\t%{NUMBER:AnalyzerTemp:float}\t%{NUMBER:AnalyzerTempFiltered:float}\t%{NUMBER:AnalyzerTempDelay:float}\t%{NUMBER:CEPSTempSensor:float}\t%{NUMBER:QuadDetectorTemp:float}%{BONUS}
			  ''']

          grok_custom_patterns = '''
			         SCINUM (?:[0-9eE.+-]*)
			         BONUS (.*)
			         '''

